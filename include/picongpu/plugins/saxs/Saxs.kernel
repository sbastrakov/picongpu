/* Copyright 2013-2020 Axel Huebl, Heiko Burau, Rene Widera, Richard Pausch,
 *                     Klaus Steiniger, Felix Schmitt, Benjamin Worpitz,
 *                     Juncheng E, Sergei Bastrakov
 *
 * This file is part of PIConGPU.
 *
 * PIConGPU is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * PIConGPU is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with PIConGPU.
 * If not, see <http://www.gnu.org/licenses/>.
 */

#pragma once

#include "picongpu/simulation_defines.hpp"

#include <pmacc/dimensions/DataSpaceOperations.hpp>
#include <pmacc/mappings/threads/ForEachIdx.hpp>
#include <pmacc/mappings/threads/IdxConfig.hpp>
#include <pmacc/memory/Array.hpp>
#include <pmacc/memory/shared/Allocate.hpp>
#include <pmacc/nvidia/atomic.hpp>
#include <pmacc/nvidia/functors/Add.hpp>

#include <cstdint>


namespace picongpu
{
namespace plugins
{
namespace saxs
{
namespace detail
{

    //! Internal representation of results
    struct Result
    {
        float_X sumfcoskr = 0._X;
        float_X sumfsinkr = 0._X;
        float_X totalWeighting = 0._X;
        uint32_t totalNumMacroparticles = 0u;

        Result & operator+=( Result const & other )
        {
            sumfcoskr += other.sumfcoskr;
            sumfsinkr += other.sumfsinkr;
            totalWeighting += other.totalWeighting;
            totalNumMacroparticles += other.totalNumMacroparticles;
            return *this;
        }

    };

    template<
        uint32_t T_numWorkers,
        typename T_Acc,
        typename ParBox,
        typename T_Mapping,
        typename T_CachedPositionArray,
        typename T_CachedWeightingArray
    >
    DINLINE Result processSupercell(
        T_Acc const &acc,
        DataSpace< simDim > const & idx,
        DataSpace< simDim > const & globalOffset,
        T_Mapping mapper,
        ParBox pb,
        T_CachedPositionArray & cachedR,
        T_CachedWeightingArray & cachedWeighting,
        float3_X q_min,
        float3_X q_step,
        DataSpace< 3 > numVectors
    )
    {
        using namespace pmacc::mappings::threads;

        uint32_t const workerIdx = threadIdx.x;
        uint32_t const globalWorkerIdx = blockIdx.x * blockDim.x + threadIdx.x;

        Result result;

        auto const guardingSuperCells = mapper.getGuardingSuperCells();
        auto const offset = globalOffset +
            ( ( idx - guardingSuperCells ) * SuperCellSize::toRT() );

        typename ParBox::FramePtr frame = pb.getLastFrame( idx );

        // number of particles in current frame
        auto particlesInFrame = pb.getSuperCell( idx ).getSizeLastFrame();

        // go to next supercell
        while( frame.isValid() )
        {
            __syncthreads();

            result.totalNumMacroparticles += particlesInFrame;

            // Cache particle data of this frame to shared memory
            constexpr uint32_t frameSize =
                pmacc::math::CT::volume< SuperCellSize >::type::value; /// fix computation from particle box

            using ParticleDomCfg = IdxConfig<
                frameSize,
                T_numWorkers
            >;
            ForEachIdx< ParticleDomCfg > forEachParticle{ workerIdx };
            forEachParticle([&](uint32_t const linearIdx, uint32_t const)
            {
                if( linearIdx < particlesInFrame )
                {
                    auto particle = frame[ linearIdx ];
                    auto const cellIdx = particle[ localCellIdx_ ];
                    auto const pos = particle[ position_ ];
                    // calculate global position of cell
                    DataSpace<simDim> const globalPos(
                        offset +
                        DataSpaceOperations<simDim>::template map<
                        SuperCellSize>(cellIdx));
                    // Set z component to zero for 2D
                    cachedR[ linearIdx ][ 2 ] = 0.0;
                    for( auto dim = 0u; dim < simDim; ++dim )
                        cachedR[ linearIdx ][ dim ] =
                        (static_cast< float_X >(globalPos[dim]) + pos[dim]) * cellSize[dim];
                    cachedWeighting[ linearIdx ] = particle[ weighting_ ];

                }
            });

            __syncthreads(); // wait till every thread has loaded its
                             // particle data

            // conversion multiplier from PIC unit length to angstrom
            constexpr float_X meter2angstrom = 1e10_X;
            constexpr float_X lengthToAngstrom = meter2angstrom * UNIT_LENGTH;

            auto const q = getQ(
                globalWorkerIdx,
                q_min,
                q_step,
                numVectors
            );

            // Particle loop: thread runs through loaded particle data
            for( auto particleIdx = 0u; particleIdx < particlesInFrame; ++particleIdx )
            {
                /// todo use dot product
                auto const dotkr = (
                    q[ 0 ] * cachedR[ particleIdx ][ 0 ] +
                    q[ 1 ] * cachedR[ particleIdx ][ 1 ] +
                    q[ 2 ] * cachedR[ particleIdx ][ 2 ]
                    ) * lengthToAngstrom;
                float_X sinValue, cosValue;
                math::sincos(
                    dotkr,
                    sinValue,
                    cosValue
                );
                result.sumfcoskr += cosValue * cachedWeighting[ particleIdx ];
                result.sumfsinkr += sinValue * cachedWeighting[ particleIdx ];
                result.totalWeighting += cachedWeighting[ particleIdx ];
            }

            // Wait until this frame is processed and go to the previous one
            __syncthreads();
            particlesInFrame = frameSize;
            frame = pb.getPreviousFrame( frame );

        } // end loop over frames

        return result;
    }


    /// TODO
    DINLINE float3_X getQ(
        uint32_t const globalWorkerIdx,
        float3_X & const qMin,
        float3_X & const qStep,
        pmacc::DataSpace< 3 > & const numVectors
    )
    {
        pmacc::DataSpace< 3 > idx;   
        idx[ 2 ] = globalWorkerIdx % numVectors.z();
        idx[ 1 ] = ( globalWorkerIdx / numVectors.z() ) % numVectors.y();
        idx[ 0 ] = globalWorkerIdx / ( numVectors.z() * numVectors.y() );
        return qMin + qStep *
            pmacc::algorithms::precisionCast::precisionCast< float_X >( idx );
    }

} // namespace detail

    /** calculate the scattering of a species
     *
     * @tparam T_numWorkers number of workers
     */
    template< uint32_t T_numWorkers >
    struct KernelSaxs
    {
        /**
         * The SAXS kernel calculates for all particles on the device the
         * scattering intensity for input calculation ranges.
         * The parallelization is as follows:
         *  - The number of threads per block is equal to the number of cells per
         *    super cells which is also equal to the number of particles per frame
         *
         * The procedure starts with calculating unique ids for the threads and
         * initializing the shared memory.
         * Then a loop over all super cells starts.
         * Every thread loads a particle from that super cell and calculates its
         * scattering structure factor.
         * For every Particle
         * exists therefore a unique space within the shared memory.
         * After that, a thread calculates for a specific scattering vector of all
         * particles.
         */
        template <
            typename ParBox,
            typename DBox,
            typename DBox_np,
            typename DBox_nmp,
            typename Mapping,
            typename T_Acc>
        DINLINE
        void
        operator()(
            T_Acc const &acc,
            ParBox pb,
            DBox sumfcoskr,
            DBox sumfsinkr,
            DBox_np np,
            DBox_nmp nmp,
            DataSpace< simDim > globalOffset,
            Mapping mapper,
            DataSpace< simDim > simBoxSize,
            float3_X qMin,
            float3_X qStep,
            DataSpace< 3 > numVectors
        ) const
        {
            constexpr uint32_t frameSize =
                pmacc::math::CT::volume< SuperCellSize >::type::value; /// fix computation from particle box

            uint32_t const globalWorkerIdx = blockIdx.x * blockDim.x + threadIdx.x;

            // vectorial part of the integrand in the Jackson formula
            using PositionArray = memory::Array<
                float3_X,
                frameSize
            >;
            PMACC_SMEM(
                acc,
                cachedR,
                PositionArray
            );

            using WeightingArray = memory::Array<
                float_X,
                frameSize
            >;
            PMACC_SMEM(
                acc,
                cachedWeighting,
                WeightingArray
            );


            /* number of super cells on GPU per dimension (still including guard
             * cells) remove both guards from count [later one sided guard needs to
             * be added again]
             */
            auto const guardingSuperCells = mapper.getGuardingSuperCells();
            auto const superCellsCount =
                mapper.getGridSuperCells() - 2 * guardingSuperCells;

            // get absolute number of relevant super cells
            auto const numSuperCells = superCellsCount.productOfComponents();

            detail::Result result;

            for( auto supercellLinearIdx = 0; supercellLinearIdx < numSuperCells; ++supercellLinearIdx )
            {             
                auto const idxWithGuard = DataSpaceOperations< simDim >::map(
                    superCellsCount,
                    supercellLinearIdx
                ) + guardingSuperCells;

                auto const supercellResult = detail::processSupercell< T_numWorkers >(
                    acc,
                    idxWithGuard,
                    globalOffset,
                    mapper,
                    pb,
                    cachedR,
                    cachedWeighting,
                    qMin,
                    qStep,
                    numVectors
                );
               /* Note: summing up for each supercell from scratch has an added benefit
                * of reducing summation errors compared to a straighforward summation
                */
                result += supercellResult;
                
            }

            // write results to global memory
            sumfcoskr[ globalWorkerIdx ] = result.sumfcoskr;
            sumfsinkr[ globalWorkerIdx ] = result.sumfsinkr;
            // total weight of particles is written by a single thread per GPU
            if( globalWorkerIdx == 0 )
            {
                np[ 0 ] = result.totalWeighting;
                nmp[ 0 ] = result.totalNumMacroparticles;
            }

        }
    };

} // namespace saxs
} // namespae plugins
} // namespace picongpu
